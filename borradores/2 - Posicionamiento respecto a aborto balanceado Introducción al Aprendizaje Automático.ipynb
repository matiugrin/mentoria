{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introducción"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En la siguiente notebook se presentará la consigna a seguir para el tercer práctico del proyecto, correspondiente a la materia Introducción al Aprendizaje Automático. El objetivo consiste en explorar la aplicación de diferentes métodos de aprendizaje supervisado aprendidos en el curso, a través de experimentos reproducibles, y evaluando a su vez la conveniencia de uno u otro, así como la selección de diferentes hiperparámetros a partir del cálculo de las métricas pertinentes.\n",
    "\n",
    "En este caso, enfrentamos un problema de clasificación binario de posicionamiento respecto de un tópico. Para este práctico vamos a utilizar únicamente los datos etiquetados, que ya vienen divididos en train y test. Buscamos analizar distintos problemas que puedan surgir como el desbalanceo de clases\n",
    "\n",
    "\n",
    "## Organización\n",
    "\n",
    "El trabajo va a estar organizado en dos grandes secciones: preprocesamiento y aplicación de los clasificadores.\n",
    "\n",
    "#### Preprocesamiento\n",
    "En la parte de preprocesamiento lo que vamos a hacer va a ser:\n",
    "\n",
    "1 - Obtener el dataset\n",
    "\n",
    "2 - Tokenizar\n",
    "\n",
    "3 - Aplicar alguna curación\n",
    "\n",
    "4 - Balanceo de clases\n",
    "\n",
    "5 - Representar el texto como vector: CountVectorizer\n",
    "\n",
    "6 - Optativo: se puede representar el texto de otras maneras? Embeddings!\n",
    "\n",
    "#### Clasificadores\n",
    "\n",
    "1 - Perceptron\n",
    "\n",
    "2 - K-NN\n",
    "\n",
    "3 - Regresión Logística\n",
    "\n",
    "4 - Evaluación de los clasificadores\n",
    "\n",
    "5 - Optimización de Hiperparámetros\n",
    "\n",
    "Esto para los tres datasets CON y SIN balanceo de clases\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression, Perceptron\n",
    "from sklearn.metrics import accuracy_score, f1_score, make_scorer, classification_report\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', 10)\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = 'all'\n",
    "pd.set_option('display.max_rows', 20000)\n",
    "pd.set_option('display.max_columns', 20000)\n",
    "pd.set_option('display.max_colwidth', -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocesamiento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cargamos los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"train.csv\", sep=',', encoding=\"latin1\").fillna(method=\"ffill\")\n",
    "test = pd.read_csv(\"test.csv\", sep=',', encoding=\"latin1\").fillna(method=\"ffill\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "abortion_train = train[train[\"Target\"] == \"Legalization of Abortion\"]\n",
    "abortion_test = test[test[\"Target\"] == \"Legalization of Abortion\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "653\n",
      "280\n"
     ]
    }
   ],
   "source": [
    "print(abortion_train.shape[0])\n",
    "print(abortion_test.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sólo vamos a usar el tweet y el stance. Como encima ya tenemos dividido el corpus según el target, vamos a eliminar todas las columnas excepto tweet y stance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "abortion_train.drop(columns = [\"Target\", \"Opinion Towards\", \"Sentiment\"], inplace=True)\n",
    "abortion_test.drop(columns = [\"Target\", \"Opinion Towards\", \"Sentiment\"], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenizamos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En principio como mínimo para realizar algún tipo de preprocesamiento y luego transformar nuestros datos en algo que pueda ser tomado como input por los clasificadores que vamos a probar necesitamos dividir nuestro tweet en formato string en una lista de palabras. La división requiere tomar decisiones sobre cómo tratar anomalías. En especial en twitter donde abundan las abreviaciones, errores ortográficos, puntuaciones raras, emojis, lo que se le ocurra al usuario.\n",
    "\n",
    "Hay muchas formas distintas de tokenizar y hay clasificadores que vienen con tokenizadores especiales incorporados al punto tal de que no pueden funcionar con otra tokenización (fastText y BERT por ejemplo separan la raíz de las parabras de sus prefijos y sufijos para poder relacionar palabras similares, como asociar todas las conjugaciones de un verbo a una misma raíz).\n",
    "\n",
    "Nosotros vamos a usar uno bien simple que tiene pocas funciones pero tiene algunas funciones pensadas especialmente para redes sociales, como por ejemplo detectar emojis o separar una palabra de sus signos de puntuación o asociar muchos signos de puntuación iguales y seguidos como si fueran uno solo (por ejemplo, !!!!!).\n",
    "\n",
    "https://www.nltk.org/api/nltk.tokenize.html\n",
    "\n",
    "Hay tres parámetros que pueden explorar leyendo la documentación (los que están escritos). Prueben ver qué pasa cuando cambian cada uno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = TweetTokenizer(preserve_case=False, reduce_len=False, strip_handles=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- preserve_case = False ---> pasa a minúscula\n",
    "- reduce_len = False ---> detecta cuando un carácter está repetido más de tres veces y lo corta en a lo sumo 3 repeticiones\n",
    "- strip_handles = True ---> elimina las palabras que comienzan con @"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tweet: @tooprettyclub Are you OK with #GOP males telling you what you can and can't do with your own body?\n",
      "Tweet tokenizado: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['are',\n",
       " 'you',\n",
       " 'ok',\n",
       " 'with',\n",
       " '#gop',\n",
       " 'males',\n",
       " 'telling',\n",
       " 'you',\n",
       " 'what',\n",
       " 'you',\n",
       " 'can',\n",
       " 'and',\n",
       " \"can't\",\n",
       " 'do',\n",
       " 'with',\n",
       " 'your',\n",
       " 'own',\n",
       " 'body',\n",
       " '?']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ejemplo\n",
    "print('Tweet: '+ abortion_train[\"Tweet\"].iloc[1])\n",
    "print('Tweet tokenizado: ') \n",
    "tokenizer.tokenize(abortion_train[\"Tweet\"].iloc[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocesamiento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El preprocesamiento para twitter requiere tomar varias decisiones. Recomiendo que vean un poco el dataset y piensen con qué palabras quieren trabajar y cuales quieren remover. Les dejo el esqueleto de una función de preprocesamiento que sólo tokeniza pero que puede tomar dos parámetros optativos para remover hashtags y números.\n",
    "\n",
    "#### Ejercicio 1\n",
    "\n",
    "Agregarle a la función de preprocesamiento que borre las urls (palabras que empiecen con http). Agregarle código para que agregue o saque texto de acuerdo con al menos un criterio propuesto por ustedes (menciones a los usuarios, caritas/emojis, puntuación)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Manuela\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import emoji\n",
    "import string\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n"
     ]
    }
   ],
   "source": [
    "print(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocesar(text, remove_hashtags=True, remove_numbers=True, remove_http=True, remove_punctuation=True, remove_stopwords=True):\n",
    "    toks = tokenizer.tokenize(text) # Arma lista de palabras\n",
    "    ret = []\n",
    "    for tok in toks:\n",
    "        if tok[0] == \"#\" and remove_hashtags:  # Removemos hashtag si remove_hashtags = True\n",
    "            continue    \n",
    "        if tok.isnumeric() and remove_numbers:   # Removemos los números si remove_numbers = True\n",
    "            continue \n",
    "        if tok[:4] == \"https\" and remove_http:  # Removemos los url si remove_http = True\n",
    "            continue  \n",
    "        if tok in string.punctuation and remove_punctuation: # Removemos !\"#$%&'()*+, -./:;<=>?@[\\]^_`{|}~ si remove_punctuation=True\n",
    "            continue \n",
    "        if tok in stop_words and remove_stopwords:  # Removemos los stopwords si remove_stopwords = True\n",
    "            continue   \n",
    "        ret.append(tok) \n",
    "    return \" \".join(ret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'wordl'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ejemplo\n",
    "w = '@donald are you in the wordl??? #genial;'\n",
    "\n",
    "preprocesar(w, remove_hashtags = True,\n",
    "               remove_numbers=True, \n",
    "               remove_http=True, \n",
    "               remove_punctuation=True,\n",
    "               remove_stopwords=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Falta eliminar los emoji:\n",
    "- https://towardsdatascience.com/a-beginners-guide-to-preprocessing-text-data-using-nlp-tools-5cb52a8d3cd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hacer esto para todos los datasets, train y test de los 3 tópicos\n",
    "abortion_train[\"Tweet_procesado\"] = abortion_train[\"Tweet\"].apply(lambda x: preprocesar(x))\n",
    "abortion_test[\"Tweet_procesado\"] = abortion_test[\"Tweet\"].apply(lambda x: preprocesar(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1b5b9dcb148>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "sns.countplot(abortion_train.Stance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1b5b9d3b7c8>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(abortion_test.Stance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Balanceo de clases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En el práctico anterior ya analizaron la distribución de las clases según cada target (tópico) del dataset. Queremos explorar la posibilidad de hacer un balanceo de clases. Para eso, analizamos tópico por tópico si esto es posible y las dificultades que tiene.\n",
    "\n",
    "Para el dataset de feminismo, tenemos dos versiones de train, una con correcciones y otra sin. En la versión con correcciones cambia el balanceo de las clases a algo más equitativo que en su version original. Por este motivo, vamos a descartar hacer un balanceo de clases en este dataset.  ## dónde está la segunda versión???\n",
    "\n",
    "Para el dataset de cambio climático tenemos un desbalanceo tan grande que, por ejemplo, sólo tenemos 11 ejemplos de la clase Against (el 6,5% del corpus). El problema que tiene una distribución tan desigual es que resulta dificil aplicar técnicas como el subsampling porque nos quedaríamos con 33 tweets de entrenamiento, o el oversampling porque para que las clases queden parejas, deberíamos repetir un mismo tweet muchas veces.\n",
    "\n",
    "Por lo tanto, nos queda el corpus de aborto:\n",
    "\n",
    "#### Ejercicio 2\n",
    "\n",
    "Hacer subsampling del corpus de aborto y guardarlo como un nuevo dataset. A partir de ahora, todos los experimentos que corran deberán correrlos además de para los tres corpus respectivos a cada tópico, también para este nuevo corpus de aborto con sus clases balanceadas. Luego vamos a comparar los resultados obtenidos con y sin balanceo de clases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = abortion_train[abortion_train.Stance == 'AGAINST'].sample(n=175, random_state=1)\n",
    "df2 = abortion_train[(abortion_train.Stance == 'FAVOR') | (abortion_train.Stance == 'NONE')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(175, 3)\n",
      "(298, 3)\n"
     ]
    }
   ],
   "source": [
    "print(df1.shape)\n",
    "print(df2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "abortion_train_balanced = pd.concat([df1,df2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(473, 3)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abortion_train_balanced.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "280"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abortion_test.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1b5b9eac848>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(abortion_train_balanced.Stance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1b5b8f12708>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(abortion_test.Stance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "abortion_train_balanced[\"Tweet_procesado\"] = abortion_train_balanced[\"Tweet\"].apply(lambda x: preprocesar(x))\n",
    "abortion_test[\"Tweet_procesado\"] = abortion_test[\"Tweet\"].apply(lambda x: preprocesar(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Representación como vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los algoritmos de Machine Learning trabajan con espacios vectoriales. Entonces siempre que trabajemos con Procesamiento de Lenguaje Natural, como es nuestro caso, se plantea la cuestión de cómo representar texto con números. Hay muchas maneras de hacer esto y es un campo que sigue evolucionando con el tiempo. Una opción muy básica es asignarle a cada palabra que aparece en nuestro dataset un número según el orden en el que aparecen. Luego, una oración es un vector de índices de esas palabras. Pero el problema que tiene esto es que los algoritmos de Machine Learning también requieren que los vectores tengan una longitud fija, con lo cual hay que recortar la oración o agregarle ceros al final. Por eso un enfoque clásico para representar texto es el Bag Of Words: un vector de bits del tamaño de todo nuestro vocabulario que tiene un uno si la palabra está en la oración y un 0 si no está.\n",
    "\n",
    "- https://es.wikipedia.org/wiki/Modelo_bolsa_de_palabras\n",
    "- https://scikit-learn.org/stable/modules/feature_extraction.html#text-feature-extraction\n",
    "\n",
    "En particular, vamos a usar la libreria CountVectorizer que implementa el Bag Of Words de manera esparsa (eficiente) y le agrega varios features que van a sernos muy útiles:\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html\n",
    "\n",
    "En particular, vamos a usar los parámetros min_df y max_df que se corresponden con min y max document frequency. Ámbos toman valores entre 0 y 1 y estipulan el rango de frecuencia de aparición de una palabra dentro de un documento que vamos a aceptar. Es decir, si min_df es 0.005, todas las palabras que representen menos de un 0,5% de las palabras totales serán descartadas. Por el otro lado, si max_df es 0.35, todas las palabras que representen más de un 35% del total de palabras serán descartadas. Nos interesa descartar las palabras con demasiada frecuencia porque probablemente no tengan valor en términos de la entropía que aportan (es decir, no aportan información: pueden ser conectores, artículos, etc.) y las que tienen muy poca frecuencia porque pueden ser outliers, palabras demasiado específicas que no aportan a la tarea que queremos desarrollar.\n",
    "\n",
    "Las Bag Of Words, sin embargo, tienen un problema importante: no preservan el contexto y la relación semántica de las palabras entre sí. Este problema dio lugar a otros enfoques como los embeddings sobre los cuales les voy a dejar algunas cosas para que lean al final de manera optativa por si les da curiosidad. Incluso, luego de los embeddings, surgieron recientemente los contextualized embeddings que además de considerar la relación semántica, consideran el orden puntual dentro de la oración.\n",
    "\n",
    "Pero volviendo a las Bag Of Words, se puede hacer un pequeño \"truco\" para tener en cuenta, al menos parcialmente, algunas frases o expresiones con el orden en el que aparecen: el parámetro ngram_range calcula la frecuencia de ngramas. Resulta muy útil para descubrir frases o expresiones comunes (además de las palabras comunes). Además, en combinación con el parámetro \"analyzer\" se pueden usar como ngramas de palabras o de caracteres.\n",
    "\n",
    "#### Ejercicio 3\n",
    "\n",
    "Explorar los hiperparámetros de CountVectorizer. Ir modificando los valores de min_df, max_df y ngram-range. Observar cómo cambia el tamaño del vector.\n",
    "\n",
    "NOTA: Como el tamaño del vector (es decir, el vocabulario) debe ser igual para el entrenamiento como para el test, tenemos que vectorizar al mismo tiempo el dataset de train y de test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_train_abortion_balanced = abortion_train_balanced[\"Tweet_procesado\"]\n",
    "text_test_abortion = abortion_test[\"Tweet_procesado\"]\n",
    "\n",
    "vectorizer = CountVectorizer(\n",
    "    binary=True, min_df=0.0075, max_df=0.75, ngram_range=(1, 10),\n",
    "    #stop_words=stopwords.words('spanish')\n",
    ")\n",
    "\n",
    "X_abortion_balanced = vectorizer.fit_transform([*text_train_abortion_balanced, *text_test_abortion])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "VEC_train_abortion_balanced = X_abortion_balanced[:len(text_train_abortion_balanced)]\n",
    "VEC_test_abortion = X_abortion_balanced[len(text_train_abortion_balanced):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(753, 186)\n",
      "{'pregnancy': 121, 'time': 159, 'without': 175, 'can': 26, 'force': 53, 'someone': 140, 'mean': 101, 'many': 97, 'hope': 70, 'choose': 32, 'life': 85, 'rt': 134, 'unborn': 162, 'children': 30, 'rights': 133, 'world': 181, 'law': 81, 'god': 61, 'men': 103, 'think': 158, 'women': 178, 'yes': 185, 'right': 132, 'get': 57, 'little': 87, 'ones': 115, 'even': 47, 'nothing': 113, 'medical': 102, 'care': 27, 'support': 144, 'human': 71, 'lives': 89, 'alive': 2, 'conception': 34, 'abortion': 0, 'issue': 75, 'that': 152, 'like': 86, 'work': 180, 'day': 37, 'love': 92, 'wrong': 183, 'mother': 105, 'texas': 149, 'anti': 8, 'call': 25, 'babies': 13, 'responsible': 131, 'enough': 44, 'take': 146, 'baby': 14, 'sex': 139, 'something': 141, 'must': 108, 'dead': 39, 'know': 80, 'womb': 177, 'human life': 72, 'new': 112, 'thank': 150, 'another': 7, 'equal': 45, 'freedom': 54, 'stop': 143, 'killing': 79, 'say': 137, 'choice': 31, 'legal': 83, 'way': 168, 'pro': 124, 'away': 12, 'pro life': 126, 'body': 23, 'innocent': 74, 'people': 116, 'safe': 135, 'kill': 77, 'we': 169, 're': 128, 'going': 62, 'we re': 170, 'well': 171, 'abortions': 1, 'would': 182, 'always': 5, 'truth': 161, 'illegal': 73, 'fetus': 52, 'child': 29, 'murder': 107, 'made': 93, 'go': 60, 'best': 17, 'mom': 104, 'fucking': 56, 'killed': 78, 'women rights': 179, 'one': 114, 'change': 28, 'never': 111, 'need': 110, 'marriage': 98, 'make': 94, 'woman': 176, 'bodily': 21, 'autonomy': 11, 'bodily autonomy': 22, 'heart': 68, 'please': 118, 'still': 142, 'nation': 109, 'today': 160, 'let': 84, 'want': 166, 'could': 36, 'come': 33, 'laws': 82, 'born': 24, 'person': 117, 'matter': 99, 'live': 88, 'see': 138, 'much': 106, 'really': 129, 'believe': 16, 'pray': 120, 'every': 49, 'll': 91, 'put': 127, 'said': 136, 'thing': 156, 'pregnant': 122, 'there': 153, 'black': 20, 'taking': 147, 'whole': 174, 'already': 3, 'death': 41, 'us': 164, 'give': 59, 'tell': 148, 'ppl': 119, 'pro choice': 125, 'good': 63, 'great': 65, 'days': 38, 'sure': 145, 'man': 96, 'help': 69, 'dear': 40, 'government': 64, 'happy': 66, 'control': 35, 'america': 6, 'year': 184, 'religious': 130, 'may': 100, 'effect': 43, 'birth': 18, 'thanks': 151, 'wants': 167, 'they': 154, 'they re': 155, 'living': 90, 'family': 51, 'pregnant people': 123, 'health': 67, 'kids': 76, 'decisions': 42, 'back': 15, 'also': 4, 'making': 95, 'what': 172, 'what best': 173, 'ur': 163, 'ever': 48, 'anything': 10, 'use': 165, 'fuck': 55, 'everyone': 50, 'getting': 58, 'anti choice': 9, 'things': 157, 'birth control': 19, 'especially': 46}\n"
     ]
    }
   ],
   "source": [
    "print(X_abortion_balanced.shape)\n",
    "print(vectorizer.vocabulary_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EXTRA: Word Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los embeddings de palabras son algo bastante nuevo en el campo del Procesamiento Del Lenguaje Natural (ultimos 10 años) pero fueron algo totalmente revolucionario que cambio absolutamente la disciplina. Desde que aparecieron las primeras versiones de embeddings (word2vec, glove, varias otras) surgieron muchas versiones distintas hechas con diversos algoritmos y técnicas. Pero todos tienen algo en común: tratan de captar la semántica de una palabra representandola con un vector (un número) que se calcula en base a los valores de las palabras que aparecen en el contexto de esa palabra. O sea, para cada palabra se calcula de manera iterativa un valor sobre la base de qué palabras aparecen antes y después en miles y miles de textos que se usan para entrenar los embeddings. Esos valores luego se exportan y se usan como representación de las palabras.\n",
    "\n",
    "No es del alcance de este trabajo práctico meterse en este tema, que correspondería más a un curso introductorio de Procesamiento del Lenguaje Natural y ya no a Machine Learning, pero me pareció interesante comentarselos como una alternativa (muy muy) frecuente frente al problema de decidir como representar texto con números.\n",
    "\n",
    "Si les interesa y quieren leer/investigar más al respecto, aca hay una clase del curso de PLN de Standford:\n",
    "https://www.youtube.com/watch?v=ERibwqs9p38&list=PL3FW7Lu3i5Jsnh1rnUwq_TcylNr7EkRe6&index=2\n",
    "\n",
    "La clase está buena aunque tiene bastante matemática. Es más que nada para que se entienda el concepto igualmente"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clasificadores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación van a realizar experimentos con tres clasificadores básicos. Para cada uno van a tener que probar una serie de hiperparámetros. Les incluyo la documentación para que puedan leer qué es cada hiperparámetro que están probando. Luego de cada corrida, evaluan el clasificador con cuatro métricas: Accuracy Score, F1 micro, F1 macro y el promedio del F1 de la clase Favor con el F1 de la clase Against. La idea es que vayan cambiando los valores de un hiperparámetro dejando fijos el resto y vean cómo ese cambio impacta en las métricas. Finalmente, para cada clasificador escriban un pequeño informe planteando cuan sensible es cada parámetro respecto de cada métrica, por qué piensan que es así de sensible y cuales son los mejores valores que encontraron. Finalmente, elijan el clasificador que les parezca más adecuado para esta tarea y justifiquen su elección. Para ese clasificador que hayan elegido van a probar luego, una busqueda más exhaustiva de hiperparámetros usando Grid Search. Este procedimiento deben hacerlo **al menos** para **dos de los cuatro** datasets con los que venimos trabajando (aborto, aborto balanceado, cambio climático y feminismo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perceptron"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Perceptron.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Perceptron(alpha=0.001, class_weight=None, early_stopping=False, eta0=1.0,\n",
       "           fit_intercept=True, max_iter=100, n_iter_no_change=5, n_jobs=None,\n",
       "           penalty='l2', random_state=0, shuffle=True, tol=0.1,\n",
       "           validation_fraction=0.1, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train = abortion_train_balanced[\"Stance\"]\n",
    "y_test = abortion_test[\"Stance\"]\n",
    "\n",
    "# En principio, pueden utilizar el módulo que sigue, con los parámetros por defecto y los que definan a continuación:\n",
    "penalty = 'l2' # No cambia con las otras opciones (None, l2, y elasticnet)\n",
    "alpha = 0.001   # A medida que aumenta es test da mejor que el train si penalty es l1 o l2, con none no es sensible\n",
    "                # A medida que disminuye overfittea si penalty es l1 o l2, con none no es sensible\n",
    "max_iter = 100  # No cambia con None ni con l2 pero con l1 mientras menos iteraciones menos overfiteo\n",
    "tol = 0.1  # Mientras más chico más overfiteo con el l2 \n",
    "\n",
    "model = Perceptron(penalty = penalty, alpha = alpha, fit_intercept=True, max_iter = max_iter, tol = tol, shuffle=True, random_state=0, class_weight=None, warm_start=False)\n",
    "model.fit(VEC_train_abortion_balanced, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy para conjunto de entrenamiento: 0.71\n",
      "F1 micro para conjunto de entrenamiento: 0.71\n",
      "F1 macro para conjunto de entrenamiento: 0.70\n",
      "F1 average para conjunto de entrenamiento: 0.69\n",
      "Accuracy para conjunto de test: 0.54\n",
      "F1 micro para conjunto de test: 0.54\n",
      "F1 macro para conjunto de test: 0.51\n",
      "F1 average para conjunto de test: 0.54\n"
     ]
    }
   ],
   "source": [
    "y_pred_train =  model.predict(VEC_train_abortion_balanced)\n",
    "accuracy_train = accuracy_score(y_train, y_pred_train)\n",
    "f1_train_micro = f1_score(y_train, y_pred_train, average=\"micro\", labels=[\"NONE\", \"AGAINST\", \"FAVOR\"])\n",
    "f1_train_macro = f1_score(y_train, y_pred_train, average=\"macro\", labels=[\"NONE\", \"AGAINST\", \"FAVOR\"])\n",
    "f1_train = f1_score(y_train, y_pred_train, average=None, labels=[\"NONE\", \"AGAINST\", \"FAVOR\"])\n",
    "f1_train_average = (f1_score(y_train, y_pred_train, average=None, labels=[\"AGAINST\"]) + f1_score(y_train, y_pred_train, average=None, labels= [\"FAVOR\"]))/2\n",
    "\n",
    "print(\"Accuracy para conjunto de entrenamiento: %.2f\" % accuracy_train)\n",
    "print(\"F1 micro para conjunto de entrenamiento: %.2f\" % f1_train_micro)\n",
    "print(\"F1 macro para conjunto de entrenamiento: %.2f\" % f1_train_macro)\n",
    "print(\"F1 average para conjunto de entrenamiento: %.2f\" % f1_train_average)\n",
    "\n",
    "y_pred_test =  model.predict(VEC_test_abortion)\n",
    "accuracy_test = accuracy_score(y_test, y_pred_test)\n",
    "f1_test_micro = f1_score(y_test, y_pred_test, average=\"micro\", labels=[\"NONE\", \"AGAINST\", \"FAVOR\"])\n",
    "f1_test_macro = f1_score(y_test, y_pred_test, average=\"macro\", labels=[\"NONE\", \"AGAINST\", \"FAVOR\"])\n",
    "f1_test = f1_score(y_test, y_pred_test, average=None, labels=[\"NONE\", \"AGAINST\", \"FAVOR\"])\n",
    "f1_test_average = (f1_score(y_test, y_pred_test, average=None, labels=[\"AGAINST\"]) + f1_score(y_test, y_pred_test, average=None, labels= [\"FAVOR\"]))/2\n",
    "\n",
    "print(\"Accuracy para conjunto de test: %.2f\" % accuracy_test)\n",
    "print(\"F1 micro para conjunto de test: %.2f\" % f1_test_micro)\n",
    "print(\"F1 macro para conjunto de test: %.2f\" % f1_test_macro)\n",
    "print(\"F1 average para conjunto de test: %.2f\" % f1_test_average)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-NN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='cosine',\n",
       "                     metric_params=None, n_jobs=None, n_neighbors=3, p=2,\n",
       "                     weights='uniform')"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_neighbors = 3 # Cantidad de vecinos a tener en cuenta\n",
    "                # A medida que disminuye overfittea y a medida que aumenta los scores empeoran\n",
    "metric = 'cosine'     # Medida de distancia. Algunas opciones: cosine, euclidean, manhattan.\n",
    "\n",
    "model = KNeighborsClassifier(n_neighbors=n_neighbors, metric=metric)\n",
    "model.fit(VEC_train_abortion_balanced, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy para conjunto de entrenamiento: 0.72\n",
      "F1 micro para conjunto de entrenamiento: 0.72\n",
      "F1 macro para conjunto de entrenamiento: 0.72\n",
      "F1 average para conjunto de entrenamiento: 0.72\n",
      "Accuracy para conjunto de test: 0.61\n",
      "F1 micro para conjunto de test: 0.61\n",
      "F1 macro para conjunto de test: 0.50\n",
      "F1 average para conjunto de test: 0.60\n"
     ]
    }
   ],
   "source": [
    "y_pred_train =  model.predict(VEC_train_abortion_balanced)\n",
    "accuracy_train = accuracy_score(y_train, y_pred_train)\n",
    "f1_train_micro = f1_score(y_train, y_pred_train, average=\"micro\", labels=[\"NONE\", \"AGAINST\", \"FAVOR\"])\n",
    "f1_train_macro = f1_score(y_train, y_pred_train, average=\"macro\", labels=[\"NONE\", \"AGAINST\", \"FAVOR\"])\n",
    "f1_train = f1_score(y_train, y_pred_train, average=None, labels=[\"NONE\", \"AGAINST\", \"FAVOR\"])\n",
    "f1_train_average = f1_train_average = (f1_score(y_train, y_pred_train, average=None, labels=[\"AGAINST\"]) + f1_score(y_train, y_pred_train, average=None, labels= [\"FAVOR\"]))/2\n",
    "\n",
    "print(\"Accuracy para conjunto de entrenamiento: %.2f\" % accuracy_train)\n",
    "print(\"F1 micro para conjunto de entrenamiento: %.2f\" % f1_train_micro)\n",
    "print(\"F1 macro para conjunto de entrenamiento: %.2f\" % f1_train_macro)\n",
    "print(\"F1 average para conjunto de entrenamiento: %.2f\" % f1_train_average)\n",
    "\n",
    "y_pred_test =  model.predict(VEC_test_abortion)\n",
    "accuracy_test = accuracy_score(y_test, y_pred_test)\n",
    "f1_test_micro = f1_score(y_test, y_pred_test, average=\"micro\", labels=[\"NONE\", \"AGAINST\", \"FAVOR\"])\n",
    "f1_test_macro = f1_score(y_test, y_pred_test, average=\"macro\", labels=[\"NONE\", \"AGAINST\", \"FAVOR\"])\n",
    "f1_test = f1_score(y_test, y_pred_test, average=None, labels=[\"NONE\", \"AGAINST\", \"FAVOR\"])\n",
    "f1_test_average = (f1_score(y_test, y_pred_test, average=None, labels=[\"AGAINST\"]) + f1_score(y_test, y_pred_test, average=None, labels= [\"FAVOR\"]))/2\n",
    "\n",
    "print(\"Accuracy para conjunto de test: %.2f\" % accuracy_test)\n",
    "print(\"F1 micro para conjunto de test: %.2f\" % f1_test_micro)\n",
    "print(\"F1 macro para conjunto de test: %.2f\" % f1_test_macro)\n",
    "print(\"F1 average para conjunto de test: %.2f\" % f1_test_average)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=10,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "penalty =  'l2' # Tipo de regularización: l1 (valor absoluto), l2 (cuadrados).\n",
    "                  # Con none overfitea, l1 y elasticnet no los soporta\n",
    "alpha =  10 # Parámetro de regularización. También denominado como parámetro `lambda`. Debe ser mayor que 0.\n",
    "            # A medida que disminuye overfitea y a medida que aumenta empeora\n",
    "max_iter =  10 # Cantidad máxima de iteraciones del algoritmo.\n",
    "               # No es sensible para valores muy altos y para valores bajos empeora\n",
    "tol =  0.0001 # Precisión del algoritmo (error mínimo entre una iteración y la siguiente).\n",
    "        # Para valores chicos no es sensible y para valores altos empeora\n",
    "model = LogisticRegression(penalty=penalty, C=1./alpha, max_iter=max_iter, tol=tol)\n",
    "model.fit(VEC_train_abortion_balanced, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy para conjunto de entrenamiento: 0.74\n",
      "F1 micro para conjunto de entrenamiento: 0.74\n",
      "F1 macro para conjunto de entrenamiento: 0.73\n",
      "F1 average para conjunto de entrenamiento: 0.69\n",
      "Accuracy para conjunto de test: 0.53\n",
      "F1 micro para conjunto de test: 0.53\n",
      "F1 macro para conjunto de test: 0.52\n",
      "F1 average para conjunto de test: 0.56\n"
     ]
    }
   ],
   "source": [
    "y_pred_train =  model.predict(VEC_train_abortion_balanced)\n",
    "accuracy_train = accuracy_score(y_train, y_pred_train)\n",
    "f1_train_micro = f1_score(y_train, y_pred_train, average=\"micro\", labels=[\"NONE\", \"AGAINST\", \"FAVOR\"])\n",
    "f1_train_macro = f1_score(y_train, y_pred_train, average=\"macro\", labels=[\"NONE\", \"AGAINST\", \"FAVOR\"])\n",
    "f1_train = f1_score(y_train, y_pred_train, average=None, labels=[\"NONE\", \"AGAINST\", \"FAVOR\"])\n",
    "f1_train_average = f1_train_average = (f1_score(y_train, y_pred_train, average=None, labels=[\"AGAINST\"]) + f1_score(y_train, y_pred_train, average=None, labels= [\"FAVOR\"]))/2\n",
    "\n",
    "print(\"Accuracy para conjunto de entrenamiento: %.2f\" % accuracy_train)\n",
    "print(\"F1 micro para conjunto de entrenamiento: %.2f\" % f1_train_micro)\n",
    "print(\"F1 macro para conjunto de entrenamiento: %.2f\" % f1_train_macro)\n",
    "print(\"F1 average para conjunto de entrenamiento: %.2f\" % f1_train_average)\n",
    "\n",
    "y_pred_test =  model.predict(VEC_test_abortion)\n",
    "accuracy_test = accuracy_score(y_test, y_pred_test)\n",
    "f1_test_micro = f1_score(y_test, y_pred_test, average=\"micro\", labels=[\"NONE\", \"AGAINST\", \"FAVOR\"])\n",
    "f1_test_macro = f1_score(y_test, y_pred_test, average=\"macro\", labels=[\"NONE\", \"AGAINST\", \"FAVOR\"])\n",
    "f1_test = f1_score(y_test, y_pred_test, average=None, labels=[\"NONE\", \"AGAINST\", \"FAVOR\"])\n",
    "f1_test_average = (f1_score(y_test, y_pred_test, average=None, labels=[\"AGAINST\"]) + f1_score(y_test, y_pred_test, average=None, labels= [\"FAVOR\"]))/2\n",
    "\n",
    "print(\"Accuracy para conjunto de test: %.2f\" % accuracy_test)\n",
    "print(\"F1 micro para conjunto de test: %.2f\" % f1_test_micro)\n",
    "print(\"F1 macro para conjunto de test: %.2f\" % f1_test_macro)\n",
    "print(\"F1 average para conjunto de test: %.2f\" % f1_test_average)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El algoritmo que obtuve mejores métricas es el de los vecinos más cercanos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=6, error_score=nan,\n",
       "             estimator=KNeighborsClassifier(algorithm='auto', leaf_size=30,\n",
       "                                            metric='minkowski',\n",
       "                                            metric_params=None, n_jobs=None,\n",
       "                                            n_neighbors=5, p=2,\n",
       "                                            weights='uniform'),\n",
       "             iid='deprecated', n_jobs=None,\n",
       "             param_grid={'metric': ['cosine', 'manhattan', 'euclidean',\n",
       "                                    'minkowvski'],\n",
       "                         'n_neighbors': [1, 2, 3, 4, 5, 10, 20, 100, 200]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring='f1_micro', verbose=0)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejor conjunto de parámetros:\n",
      "{'metric': 'cosine', 'n_neighbors': 20}\n",
      "\n",
      "\n",
      "Puntajes de la grilla:\n",
      "\n",
      "\n",
      "Reporte de clasificación para el mejor clasificador (sobre conjunto de evaluación):\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     AGAINST       0.86      0.50      0.64       189\n",
      "       FAVOR       0.36      0.59      0.44        46\n",
      "        NONE       0.31      0.64      0.42        45\n",
      "\n",
      "    accuracy                           0.54       280\n",
      "   macro avg       0.51      0.58      0.50       280\n",
      "weighted avg       0.69      0.54      0.57       280\n",
      "\n",
      "\n",
      "================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Para la búsqueda de los mejores parámetros, por ejemplo de logistic regression, pueden usar:\n",
    "\n",
    "exploring_params = {\n",
    "        'n_neighbors': [ 1, 2, 3, 4, 5, 10, 20, 100, 200], # Inversa del coeficiente de regularización\n",
    "        'metric': ['cosine', 'manhattan', 'euclidean', 'minkowvski'],  # Cantidad de iteraciones\n",
    "    }\n",
    "\n",
    "m = KNeighborsClassifier()\n",
    "n_cross_val =  6 # Seleccionar folds\n",
    "scoring = \"f1_micro\"\n",
    "model = GridSearchCV(m, exploring_params, cv=n_cross_val, scoring=scoring)\n",
    "    \n",
    "model.fit(VEC_train_abortion_balanced, y_train)\n",
    "\n",
    "print(\"Mejor conjunto de parámetros:\")\n",
    "print(model.best_params_, end=\"\\n\\n\")\n",
    "print()\n",
    "print(\"Puntajes de la grilla:\", end=\"\\n\\n\")\n",
    "means = model.cv_results_['mean_test_score']\n",
    "stds = model.cv_results_['std_test_score']\n",
    "print()\n",
    "print(\"Reporte de clasificación para el mejor clasificador (sobre conjunto de evaluación):\", end=\"\\n\\n\")\n",
    "y_true, y_pred = y_test, model.predict(VEC_test_abortion)\n",
    "print(classification_report(y_true, y_pred), end=\"\\n\\n\")\n",
    "\n",
    "print(\"================================================\", end=\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agregar matriz de confusión"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
