{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introducción"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En la siguiente notebook se presentará la consigna a seguir para el tercer práctico del proyecto, correspondiente a la materia Introducción al Aprendizaje Automático. El objetivo consiste en explorar la aplicación de diferentes métodos de aprendizaje supervisado aprendidos en el curso, a través de experimentos reproducibles, y evaluando a su vez la conveniencia de uno u otro, así como la selección de diferentes hiperparámetros a partir del cálculo de las métricas pertinentes.\n",
    "\n",
    "En este caso, enfrentamos un problema de clasificación binario de posicionamiento respecto de un tópico. Para este práctico vamos a utilizar únicamente los datos etiquetados, que ya vienen divididos en train y test. Buscamos analizar distintos problemas que puedan surgir como el desbalanceo de clases\n",
    "\n",
    "\n",
    "## Organización\n",
    "\n",
    "El trabajo va a estar organizado en dos grandes secciones: preprocesamiento y aplicación de los clasificadores.\n",
    "\n",
    "#### Preprocesamiento\n",
    "En la parte de preprocesamiento lo que vamos a hacer va a ser:\n",
    "\n",
    "1 - Obtener el dataset\n",
    "\n",
    "2 - Tokenizar\n",
    "\n",
    "3 - Aplicar alguna curación\n",
    "\n",
    "4 - Balanceo de clases\n",
    "\n",
    "5 - Representar el texto como vector: CountVectorizer\n",
    "\n",
    "6 - Optativo: se puede representar el texto de otras maneras? Embeddings!\n",
    "\n",
    "#### Clasificadores\n",
    "\n",
    "1 - Perceptron\n",
    "\n",
    "2 - K-NN\n",
    "\n",
    "3 - Regresión Logística\n",
    "\n",
    "4 - Evaluación de los clasificadores\n",
    "\n",
    "5 - Optimización de Hiperparámetros\n",
    "\n",
    "Esto para los tres datasets CON y SIN balanceo de clases\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression, Perceptron\n",
    "from sklearn.metrics import accuracy_score, f1_score, make_scorer, classification_report\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', 10)\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = 'all'\n",
    "pd.set_option('display.max_rows', 20000)\n",
    "pd.set_option('display.max_columns', 20000)\n",
    "pd.set_option('display.max_colwidth', -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocesamiento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cargamos los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"train.csv\", sep=',', encoding=\"latin1\").fillna(method=\"ffill\")\n",
    "test = pd.read_csv(\"test.csv\", sep=',', encoding=\"latin1\").fillna(method=\"ffill\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "abortion_train = train[train[\"Target\"] == \"Legalization of Abortion\"]\n",
    "abortion_test = test[test[\"Target\"] == \"Legalization of Abortion\"]\n",
    "\n",
    "climate_train = train[train[\"Target\"] == \"Climate Change is a Real Concern\"]\n",
    "climate_test = test[test[\"Target\"] == \"Climate Change is a Real Concern\"]\n",
    "\n",
    "feminism_train = train[train[\"Target\"] == \"Feminist Movement\"]\n",
    "feminism_test = test[test[\"Target\"] == \"Feminist Movement\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "653\n",
      "280\n",
      "395\n",
      "169\n",
      "664\n",
      "285\n"
     ]
    }
   ],
   "source": [
    "print(abortion_train.shape[0])\n",
    "print(abortion_test.shape[0])\n",
    "print(climate_train.shape[0])\n",
    "print(climate_test.shape[0])\n",
    "print(feminism_train.shape[0])\n",
    "print(feminism_test.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Target</th>\n",
       "      <th>Stance</th>\n",
       "      <th>Opinion Towards</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>919</th>\n",
       "      <td>People at the bar bitching about the heat and drought. No one utters the words #fossilfuel caused #elephantintheroom #denial #SemST</td>\n",
       "      <td>Climate Change is a Real Concern</td>\n",
       "      <td>FAVOR</td>\n",
       "      <td>1.  The tweet explicitly expresses opinion about the target, a part of the target, or an aspect of the target.</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>947</th>\n",
       "      <td>BrettGarrot: BrettGarrot: GlblWarmingNews And the tooth fairy might be causing kids to lose teeth! #carbontaxscam #Chemtrails #SemST</td>\n",
       "      <td>Climate Change is a Real Concern</td>\n",
       "      <td>AGAINST</td>\n",
       "      <td>1.  The tweet explicitly expresses opinion about the target, a part of the target, or an aspect of the target.</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>616</th>\n",
       "      <td>Delivering good jobs for Albertans, maintaining a stable economy &amp; meeting climate change strategy. Good goals. #abpoli #GHG #SemST</td>\n",
       "      <td>Climate Change is a Real Concern</td>\n",
       "      <td>FAVOR</td>\n",
       "      <td>1.  The tweet explicitly expresses opinion about the target, a part of the target, or an aspect of the target.</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>853</th>\n",
       "      <td>@DalydeGagne @2010redmittens Canada alone needs 2 invest $60 billion a year, paid for by efficiency #cdnpoli #environment #SemST</td>\n",
       "      <td>Climate Change is a Real Concern</td>\n",
       "      <td>FAVOR</td>\n",
       "      <td>1.  The tweet explicitly expresses opinion about the target, a part of the target, or an aspect of the target.</td>\n",
       "      <td>other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>805</th>\n",
       "      <td>SA has played an instrumental role in rallying other BASIC countries to strengthen South-South cooperation on matters around #SemST</td>\n",
       "      <td>Climate Change is a Real Concern</td>\n",
       "      <td>NONE</td>\n",
       "      <td>3.  The tweet is not explicitly expressing opinion. (For example, the tweet is simply giving information.)</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>646</th>\n",
       "      <td>@CBCNews @nationalpost The human mind is incapable of dealing with that of which it has no experience  #SemST</td>\n",
       "      <td>Climate Change is a Real Concern</td>\n",
       "      <td>NONE</td>\n",
       "      <td>2. The tweet does NOT expresses opinion about the target but it HAS opinion about something or someone other than the target.</td>\n",
       "      <td>other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>679</th>\n",
       "      <td>If it doesn't warm up soon @Number10gov, I want my money back on the panels for misselling. #45Minutes #dodgydata #Drtker #SemST</td>\n",
       "      <td>Climate Change is a Real Concern</td>\n",
       "      <td>NONE</td>\n",
       "      <td>2. The tweet does NOT expresses opinion about the target but it HAS opinion about something or someone other than the target.</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>965</th>\n",
       "      <td>Scorching summers for UK by end of the century! Thank Rocks I won't be here to suffer them! :-)  #SemST</td>\n",
       "      <td>Climate Change is a Real Concern</td>\n",
       "      <td>FAVOR</td>\n",
       "      <td>1.  The tweet explicitly expresses opinion about the target, a part of the target, or an aspect of the target.</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>969</th>\n",
       "      <td>RT @fadoben60: When the rate of #Utilisation exceeds the rate of #Regeneration then it calls for #DEGRADATION. #michachallen... #SemST</td>\n",
       "      <td>Climate Change is a Real Concern</td>\n",
       "      <td>NONE</td>\n",
       "      <td>2. The tweet does NOT expresses opinion about the target but it HAS opinion about something or someone other than the target.</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>630</th>\n",
       "      <td>@RegimeChangeBC @ndnstyl It's sad to be the last generation that could change but does nothing. #Auspol #SemST</td>\n",
       "      <td>Climate Change is a Real Concern</td>\n",
       "      <td>FAVOR</td>\n",
       "      <td>1.  The tweet explicitly expresses opinion about the target, a part of the target, or an aspect of the target.</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                      Tweet  \\\n",
       "919  People at the bar bitching about the heat and drought. No one utters the words #fossilfuel caused #elephantintheroom #denial #SemST      \n",
       "947  BrettGarrot: BrettGarrot: GlblWarmingNews And the tooth fairy might be causing kids to lose teeth! #carbontaxscam #Chemtrails #SemST     \n",
       "616  Delivering good jobs for Albertans, maintaining a stable economy & meeting climate change strategy. Good goals. #abpoli #GHG #SemST      \n",
       "853  @DalydeGagne @2010redmittens Canada alone needs 2 invest $60 billion a year, paid for by efficiency #cdnpoli #environment #SemST         \n",
       "805  SA has played an instrumental role in rallying other BASIC countries to strengthen South-South cooperation on matters around #SemST      \n",
       "646  @CBCNews @nationalpost The human mind is incapable of dealing with that of which it has no experience  #SemST                            \n",
       "679  If it doesn't warm up soon @Number10gov, I want my money back on the panels for misselling. #45Minutes #dodgydata #Drtker #SemST         \n",
       "965  Scorching summers for UK by end of the century! Thank Rocks I won't be here to suffer them! :-)  #SemST                                  \n",
       "969  RT @fadoben60: When the rate of #Utilisation exceeds the rate of #Regeneration then it calls for #DEGRADATION. #michachallen... #SemST   \n",
       "630  @RegimeChangeBC @ndnstyl It's sad to be the last generation that could change but does nothing. #Auspol #SemST                           \n",
       "\n",
       "                               Target   Stance  \\\n",
       "919  Climate Change is a Real Concern  FAVOR     \n",
       "947  Climate Change is a Real Concern  AGAINST   \n",
       "616  Climate Change is a Real Concern  FAVOR     \n",
       "853  Climate Change is a Real Concern  FAVOR     \n",
       "805  Climate Change is a Real Concern  NONE      \n",
       "646  Climate Change is a Real Concern  NONE      \n",
       "679  Climate Change is a Real Concern  NONE      \n",
       "965  Climate Change is a Real Concern  FAVOR     \n",
       "969  Climate Change is a Real Concern  NONE      \n",
       "630  Climate Change is a Real Concern  FAVOR     \n",
       "\n",
       "                                                                                                                   Opinion Towards  \\\n",
       "919  1.  The tweet explicitly expresses opinion about the target, a part of the target, or an aspect of the target.                  \n",
       "947  1.  The tweet explicitly expresses opinion about the target, a part of the target, or an aspect of the target.                  \n",
       "616  1.  The tweet explicitly expresses opinion about the target, a part of the target, or an aspect of the target.                  \n",
       "853  1.  The tweet explicitly expresses opinion about the target, a part of the target, or an aspect of the target.                  \n",
       "805  3.  The tweet is not explicitly expressing opinion. (For example, the tweet is simply giving information.)                      \n",
       "646  2. The tweet does NOT expresses opinion about the target but it HAS opinion about something or someone other than the target.   \n",
       "679  2. The tweet does NOT expresses opinion about the target but it HAS opinion about something or someone other than the target.   \n",
       "965  1.  The tweet explicitly expresses opinion about the target, a part of the target, or an aspect of the target.                  \n",
       "969  2. The tweet does NOT expresses opinion about the target but it HAS opinion about something or someone other than the target.   \n",
       "630  1.  The tweet explicitly expresses opinion about the target, a part of the target, or an aspect of the target.                  \n",
       "\n",
       "    Sentiment  \n",
       "919  neg       \n",
       "947  neg       \n",
       "616  pos       \n",
       "853  other     \n",
       "805  pos       \n",
       "646  other     \n",
       "679  neg       \n",
       "965  pos       \n",
       "969  neg       \n",
       "630  neg       "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "climate_train.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sólo vamos a usar el tweet y el stance. Como encima ya tenemos dividido el corpus según el target, vamos a eliminar todas las columnas excepto tweet y stance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "abortion_train.drop(columns = [\"Target\", \"Opinion Towards\", \"Sentiment\"], inplace=True)\n",
    "abortion_test.drop(columns = [\"Target\", \"Opinion Towards\", \"Sentiment\"], inplace=True)\n",
    "\n",
    "climate_train.drop(columns = [\"Target\", \"Opinion Towards\", \"Sentiment\"], inplace=True)\n",
    "climate_test.drop(columns = [\"Target\", \"Opinion Towards\", \"Sentiment\"], inplace=True)\n",
    "\n",
    "feminism_train.drop(columns = [\"Target\", \"Opinion Towards\", \"Sentiment\"], inplace=True)\n",
    "feminism_test.drop(columns = [\"Target\", \"Opinion Towards\", \"Sentiment\"], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenizamos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En principio como mínimo para realizar algún tipo de preprocesamiento y luego transformar nuestros datos en algo que pueda ser tomado como input por los clasificadores que vamos a probar necesitamos dividir nuestro tweet en formato string en una lista de palabras. La división requiere tomar decisiones sobre cómo tratar anomalías. En especial en twitter donde abundan las abreviaciones, errores ortográficos, puntuaciones raras, emojis, lo que se le ocurra al usuario.\n",
    "\n",
    "Hay muchas formas distintas de tokenizar y hay clasificadores que vienen con tokenizadores especiales incorporados al punto tal de que no pueden funcionar con otra tokenización (fastText y BERT por ejemplo separan la raíz de las parabras de sus prefijos y sufijos para poder relacionar palabras similares, como asociar todas las conjugaciones de un verbo a una misma raíz).\n",
    "\n",
    "Nosotros vamos a usar uno bien simple que tiene pocas funciones pero tiene algunas funciones pensadas especialmente para redes sociales, como por ejemplo detectar emojis o separar una palabra de sus signos de puntuación o asociar muchos signos de puntuación iguales y seguidos como si fueran uno solo (por ejemplo, !!!!!).\n",
    "\n",
    "https://www.nltk.org/api/nltk.tokenize.html\n",
    "\n",
    "Hay tres parámetros que pueden explorar leyendo la documentación (los que están escritos). Prueben ver qué pasa cuando cambian cada uno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = TweetTokenizer(preserve_case=False, reduce_len=False, strip_handles=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- preserve_case = False ---> pasa a minúscula\n",
    "- reduce_len = False ---> detecta cuando un carácter está repetido más de tres veces y lo corta en a lo sumo 3 repeticiones\n",
    "- strip_handles = True ---> elimina las palabras que comienzan con @"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tweet: @tooprettyclub Are you OK with #GOP males telling you what you can and can't do with your own body?\n",
      "Tweet tokenizado: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['are',\n",
       " 'you',\n",
       " 'ok',\n",
       " 'with',\n",
       " '#gop',\n",
       " 'males',\n",
       " 'telling',\n",
       " 'you',\n",
       " 'what',\n",
       " 'you',\n",
       " 'can',\n",
       " 'and',\n",
       " \"can't\",\n",
       " 'do',\n",
       " 'with',\n",
       " 'your',\n",
       " 'own',\n",
       " 'body',\n",
       " '?']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ejemplo\n",
    "print('Tweet: '+ abortion_train[\"Tweet\"].iloc[1])\n",
    "print('Tweet tokenizado: ') \n",
    "tokenizer.tokenize(abortion_train[\"Tweet\"].iloc[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocesamiento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El preprocesamiento para twitter requiere tomar varias decisiones. Recomiendo que vean un poco el dataset y piensen con qué palabras quieren trabajar y cuales quieren remover. Les dejo el esqueleto de una función de preprocesamiento que sólo tokeniza pero que puede tomar dos parámetros optativos para remover hashtags y números.\n",
    "\n",
    "#### Ejercicio 1\n",
    "\n",
    "Agregarle a la función de preprocesamiento que borre las urls (palabras que empiecen con http). Agregarle código para que agregue o saque texto de acuerdo con al menos un criterio propuesto por ustedes (menciones a los usuarios, caritas/emojis, puntuación)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Manuela\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import emoji\n",
    "import string\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n"
     ]
    }
   ],
   "source": [
    "print(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocesar(text, remove_hashtags=True, remove_numbers=True, remove_http=True, remove_punctuation=True, remove_stopwords=True):\n",
    "    toks = tokenizer.tokenize(text) # Arma lista de palabras\n",
    "    ret = []\n",
    "    for tok in toks:\n",
    "        if tok[0] == \"#\" and remove_hashtags:  # Removemos hashtag si remove_hashtags = True\n",
    "            continue    \n",
    "        if tok.isnumeric() and remove_numbers:   # Removemos los números si remove_numbers = True\n",
    "            continue \n",
    "        if tok[:4] == \"http\" and remove_http:  # Removemos los url si remove_http = True\n",
    "            continue  \n",
    "        if tok in string.punctuation and remove_punctuation: # Removemos !\"#$%&'()*+, -./:;<=>?@[\\]^_`{|}~ si remove_punctuation=True\n",
    "            continue \n",
    "        if tok in stop_words and remove_stopwords:  # Removemos los stopwords si remove_stopwords = True\n",
    "            continue   \n",
    "        ret.append(tok) \n",
    "    return \" \".join(ret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'wordl'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ejemplo\n",
    "w = '@donald are you in the wordl??? #genial;'\n",
    "\n",
    "preprocesar(w, remove_hashtags = True,\n",
    "               remove_numbers=True, \n",
    "               remove_http=True, \n",
    "               remove_punctuation=True,\n",
    "               remove_stopwords=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Falta eliminar los emoji:\n",
    "- https://towardsdatascience.com/a-beginners-guide-to-preprocessing-text-data-using-nlp-tools-5cb52a8d3cd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hacer esto para todos los datasets, train y test de los 3 tópicos\n",
    "abortion_train[\"Tweet_procesado\"] = abortion_train[\"Tweet\"].apply(lambda x: preprocesar(x))\n",
    "abortion_test[\"Tweet_procesado\"] = abortion_test[\"Tweet\"].apply(lambda x: preprocesar(x))\n",
    "climate_train[\"Tweet_procesado\"] = climate_train[\"Tweet\"].apply(lambda x: preprocesar(x))\n",
    "climate_test[\"Tweet_procesado\"] = climate_test[\"Tweet\"].apply(lambda x: preprocesar(x))\n",
    "feminism_train[\"Tweet_procesado\"] = feminism_train[\"Tweet\"].apply(lambda x: preprocesar(x))\n",
    "feminism_test[\"Tweet_procesado\"] = feminism_test[\"Tweet\"].apply(lambda x: preprocesar(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Stance</th>\n",
       "      <th>Tweet_procesado</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>613</th>\n",
       "      <td>We cant deny it, its really happening.  #SemST</td>\n",
       "      <td>FAVOR</td>\n",
       "      <td>cant deny really happening</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>614</th>\n",
       "      <td>RT @cderworiz: Timelines are short. Strategy must be in place by climate change conference in Paris by December. #ableg #SemST</td>\n",
       "      <td>FAVOR</td>\n",
       "      <td>rt timelines short strategy must place climate change conference paris december</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>615</th>\n",
       "      <td>SO EXCITING! Meaningful climate change action is on the way! #abpoli #GHG #SemST</td>\n",
       "      <td>FAVOR</td>\n",
       "      <td>exciting meaningful climate change action way</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>616</th>\n",
       "      <td>Delivering good jobs for Albertans, maintaining a stable economy &amp; meeting climate change strategy. Good goals. #abpoli #GHG #SemST</td>\n",
       "      <td>FAVOR</td>\n",
       "      <td>delivering good jobs albertans maintaining stable economy meeting climate change strategy good goals</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>617</th>\n",
       "      <td>@davidswann says he wants carbon fund to be spent on public transportation and renewable energy. #ejlive #ableg #SemST</td>\n",
       "      <td>FAVOR</td>\n",
       "      <td>says wants carbon fund spent public transportation renewable energy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                   Tweet  \\\n",
       "613  We cant deny it, its really happening.  #SemST                                                                                        \n",
       "614  RT @cderworiz: Timelines are short. Strategy must be in place by climate change conference in Paris by December. #ableg #SemST        \n",
       "615  SO EXCITING! Meaningful climate change action is on the way! #abpoli #GHG #SemST                                                      \n",
       "616  Delivering good jobs for Albertans, maintaining a stable economy & meeting climate change strategy. Good goals. #abpoli #GHG #SemST   \n",
       "617  @davidswann says he wants carbon fund to be spent on public transportation and renewable energy. #ejlive #ableg #SemST                \n",
       "\n",
       "    Stance  \\\n",
       "613  FAVOR   \n",
       "614  FAVOR   \n",
       "615  FAVOR   \n",
       "616  FAVOR   \n",
       "617  FAVOR   \n",
       "\n",
       "                                                                                          Tweet_procesado  \n",
       "613  cant deny really happening                                                                            \n",
       "614  rt timelines short strategy must place climate change conference paris december                       \n",
       "615  exciting meaningful climate change action way                                                         \n",
       "616  delivering good jobs albertans maintaining stable economy meeting climate change strategy good goals  \n",
       "617  says wants carbon fund spent public transportation renewable energy                                   "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "climate_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x17168a6d788>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "sns.countplot(climate_train.Stance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x171698576c8>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(abortion_train.Stance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x17169904288>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(abortion_test.Stance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x171698f7948>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(feminism_train.Stance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Balanceo de clases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En el práctico anterior ya analizaron la distribución de las clases según cada target (tópico) del dataset. Queremos explorar la posibilidad de hacer un balanceo de clases. Para eso, analizamos tópico por tópico si esto es posible y las dificultades que tiene.\n",
    "\n",
    "Para el dataset de feminismo, tenemos dos versiones de train, una con correcciones y otra sin. En la versión con correcciones cambia el balanceo de las clases a algo más equitativo que en su version original. Por este motivo, vamos a descartar hacer un balanceo de clases en este dataset.  ## dónde está la segunda versión???\n",
    "\n",
    "Para el dataset de cambio climático tenemos un desbalanceo tan grande que, por ejemplo, sólo tenemos 11 ejemplos de la clase Against (el 6,5% del corpus). El problema que tiene una distribución tan desigual es que resulta dificil aplicar técnicas como el subsampling porque nos quedaríamos con 33 tweets de entrenamiento, o el oversampling porque para que las clases queden parejas, deberíamos repetir un mismo tweet muchas veces.\n",
    "\n",
    "Por lo tanto, nos queda el corpus de aborto:\n",
    "\n",
    "#### Ejercicio 2\n",
    "\n",
    "Hacer subsampling del corpus de aborto y guardarlo como un nuevo dataset. A partir de ahora, todos los experimentos que corran deberán correrlos además de para los tres corpus respectivos a cada tópico, también para este nuevo corpus de aborto con sus clases balanceadas. Luego vamos a comparar los resultados obtenidos con y sin balanceo de clases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = abortion_train[abortion_train.Stance == 'AGAINST'].sample(n=175, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = abortion_train[(abortion_train.Stance == 'FAVOR') | (abortion_train.Stance == 'NONE')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(175, 3)\n",
      "(298, 3)\n"
     ]
    }
   ],
   "source": [
    "print(df1.shape)\n",
    "print(df2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "abortion_train_balanced = pd.concat([df1,df2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(473, 3)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abortion_train_balanced.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "280"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abortion_test.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x171699e5f88>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(abortion_train_balanced.Stance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "abortion_train_balanced[\"Tweet_procesado\"] = abortion_train_balanced[\"Tweet\"].apply(lambda x: preprocesar(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Representación como vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los algoritmos de Machine Learning trabajan con espacios vectoriales. Entonces siempre que trabajemos con Procesamiento de Lenguaje Natural, como es nuestro caso, se plantea la cuestión de cómo representar texto con números. Hay muchas maneras de hacer esto y es un campo que sigue evolucionando con el tiempo. Una opción muy básica es asignarle a cada palabra que aparece en nuestro dataset un número según el orden en el que aparecen. Luego, una oración es un vector de índices de esas palabras. Pero el problema que tiene esto es que los algoritmos de Machine Learning también requieren que los vectores tengan una longitud fija, con lo cual hay que recortar la oración o agregarle ceros al final. Por eso un enfoque clásico para representar texto es el Bag Of Words: un vector de bits del tamaño de todo nuestro vocabulario que tiene un uno si la palabra está en la oración y un 0 si no está.\n",
    "\n",
    "- https://es.wikipedia.org/wiki/Modelo_bolsa_de_palabras\n",
    "- https://scikit-learn.org/stable/modules/feature_extraction.html#text-feature-extraction\n",
    "\n",
    "En particular, vamos a usar la libreria CountVectorizer que implementa el Bag Of Words de manera esparsa (eficiente) y le agrega varios features que van a sernos muy útiles:\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html\n",
    "\n",
    "En particular, vamos a usar los parámetros min_df y max_df que se corresponden con min y max document frequency. Ámbos toman valores entre 0 y 1 y estipulan el rango de frecuencia de aparición de una palabra dentro de un documento que vamos a aceptar. Es decir, si min_df es 0.005, todas las palabras que representen menos de un 0,5% de las palabras totales serán descartadas. Por el otro lado, si max_df es 0.35, todas las palabras que representen más de un 35% del total de palabras serán descartadas. Nos interesa descartar las palabras con demasiada frecuencia porque probablemente no tengan valor en términos de la entropía que aportan (es decir, no aportan información: pueden ser conectores, artículos, etc.) y las que tienen muy poca frecuencia porque pueden ser outliers, palabras demasiado específicas que no aportan a la tarea que queremos desarrollar.\n",
    "\n",
    "Las Bag Of Words, sin embargo, tienen un problema importante: no preservan el contexto y la relación semántica de las palabras entre sí. Este problema dio lugar a otros enfoques como los embeddings sobre los cuales les voy a dejar algunas cosas para que lean al final de manera optativa por si les da curiosidad. Incluso, luego de los embeddings, surgieron recientemente los contextualized embeddings que además de considerar la relación semántica, consideran el orden puntual dentro de la oración.\n",
    "\n",
    "Pero volviendo a las Bag Of Words, se puede hacer un pequeño \"truco\" para tener en cuenta, al menos parcialmente, algunas frases o expresiones con el orden en el que aparecen: el parámetro ngram_range calcula la frecuencia de ngramas. Resulta muy útil para descubrir frases o expresiones comunes (además de las palabras comunes). Además, en combinación con el parámetro \"analyzer\" se pueden usar como ngramas de palabras o de caracteres.\n",
    "\n",
    "#### Ejercicio 3\n",
    "\n",
    "Explorar los hiperparámetros de CountVectorizer. Ir modificando los valores de min_df, max_df y ngram-range. Observar cómo cambia el tamaño del vector.\n",
    "\n",
    "NOTA: Como el tamaño del vector (es decir, el vocabulario) debe ser igual para el entrenamiento como para el test, tenemos que vectorizar al mismo tiempo el dataset de train y de test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_train_abortion = abortion_train[\"Tweet_procesado\"]\n",
    "text_test_abortion = abortion_test[\"Tweet_procesado\"]\n",
    "\n",
    "vectorizer = CountVectorizer(\n",
    "    binary=True, min_df=0.0075, max_df=0.75, ngram_range=(1, 10),\n",
    "    #stop_words=stopwords.words('spanish')\n",
    ")\n",
    "\n",
    "X_abortion = vectorizer.fit_transform([*text_train_abortion, *text_test_abortion])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "VEC_train_abortion = X_abortion[:len(text_train_abortion)]\n",
    "VEC_test_abortion = X_abortion[len(text_train_abortion):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(933, 197)\n",
      "{'law': 85, 'abortion': 2, 'ok': 120, 'can': 29, 'body': 26, 'want': 179, 'put': 137, 'born': 27, 'children': 33, 'life': 89, 'human': 74, 'right': 143, 'new': 118, 'day': 42, 'alive': 4, 'thank': 163, 'god': 65, 'another': 9, 'women': 189, 'know': 84, 'choices': 35, 'come': 38, 'one': 121, 'today': 173, 'say': 148, 'believe': 19, 'pray': 130, 'planned': 127, 'need': 116, 'human life': 75, 'rt': 145, 'give': 63, 'wrong': 194, 'live': 92, 'world': 192, 'people': 125, 'care': 30, 'religious': 141, 'rights': 144, 'love': 97, 'mother': 111, 'choice': 34, 'said': 147, 'nothing': 119, 'pregnant': 132, 'safe': 146, 'great': 69, 'pregnant people': 133, 'get': 61, 'we': 182, 'll': 95, 'mean': 106, 'abortions': 3, 'dead': 44, 'would': 193, 'force': 59, 'woman': 187, 'health': 71, 'pregnancy': 131, 'someone': 152, 'wants': 180, 'person': 126, 'marriage': 103, 'pro': 134, 'babies': 16, 'aborted': 1, 'pro life': 136, 'whole': 185, 'choose': 36, 'make': 99, 'kids': 80, 'they': 167, 're': 139, 'they re': 168, 'work': 191, 'unborn': 174, 'child': 32, 'could': 41, 'equal': 51, 'yes': 196, 'freedom': 60, 'rape': 138, 'abort': 0, 'sex': 151, 'there': 166, 'control': 40, 'without': 186, 'stop': 156, 'much': 112, 'illegal': 76, 'kill': 81, 'legal': 87, 'baby': 17, 'let': 88, 'like': 90, 'birth': 21, 'support': 157, 'killing': 83, 'made': 98, 'go': 64, 'help': 72, 'going': 66, 'stand': 154, 'really': 140, 'matter': 104, 'years': 195, 'pro choice': 135, 'see': 150, 'many': 102, 'always': 7, 'issue': 78, 'every': 55, 'we re': 183, 'mom': 110, 'medical': 107, 'men': 108, 'decisions': 47, 'fetus': 58, 'must': 114, 'long': 96, 'use': 178, 'family': 57, 'thanks': 164, 'nation': 115, 'innocent': 77, 'unborn babies': 175, 'dear': 45, 'already': 5, 'back': 18, 'sure': 158, 'texas': 162, 'also': 6, 'death': 46, 'days': 43, 'conception': 39, 'time': 172, 'end': 50, 'making': 100, 'way': 181, 'that': 165, 'best': 20, 'well': 184, 'ur': 176, 'never': 117, 'something': 153, 'anyone': 12, 'anti': 10, 'may': 105, 'ever': 54, 'anything': 13, 'even': 53, 'keep': 79, 'change': 31, 'little': 91, 'good': 67, 'us': 177, 'man': 101, 'tell': 161, 'murder': 113, 'past': 124, 'think': 171, 'ppl': 129, 'lives': 93, 'business': 28, 'still': 155, 'effect': 49, 'away': 15, 'black': 23, 'killed': 82, 'please': 128, 'happy': 70, 'taking': 160, 'take': 159, 'hope': 73, 'says': 149, 'thing': 169, 'birth control': 22, 'responsible': 142, 'government': 68, 'laws': 86, 'clinics': 37, 'millions': 109, 'women rights': 190, 'ones': 122, 'bodily': 24, 'autonomy': 14, 'bodily autonomy': 25, 'getting': 62, 'womb': 188, 'die': 48, 'america': 8, 'things': 170, 'everyone': 56, 'equality': 52, 'anti choice': 11, 'parents': 123, 'living': 94}\n"
     ]
    }
   ],
   "source": [
    "print(X_abortion.shape)  # Tener en cuenta que el número indica el índice, no la frecuencia\n",
    "print(vectorizer.vocabulary_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hacer esto mismo para los otros tres datasets (Cambio climático, feminismo y el del aborto balanceado)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EXTRA: Word Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los embeddings de palabras son algo bastante nuevo en el campo del Procesamiento Del Lenguaje Natural (ultimos 10 años) pero fueron algo totalmente revolucionario que cambio absolutamente la disciplina. Desde que aparecieron las primeras versiones de embeddings (word2vec, glove, varias otras) surgieron muchas versiones distintas hechas con diversos algoritmos y técnicas. Pero todos tienen algo en común: tratan de captar la semántica de una palabra representandola con un vector (un número) que se calcula en base a los valores de las palabras que aparecen en el contexto de esa palabra. O sea, para cada palabra se calcula de manera iterativa un valor sobre la base de qué palabras aparecen antes y después en miles y miles de textos que se usan para entrenar los embeddings. Esos valores luego se exportan y se usan como representación de las palabras.\n",
    "\n",
    "No es del alcance de este trabajo práctico meterse en este tema, que correspondería más a un curso introductorio de Procesamiento del Lenguaje Natural y ya no a Machine Learning, pero me pareció interesante comentarselos como una alternativa (muy muy) frecuente frente al problema de decidir como representar texto con números.\n",
    "\n",
    "Si les interesa y quieren leer/investigar más al respecto, aca hay una clase del curso de PLN de Standford:\n",
    "https://www.youtube.com/watch?v=ERibwqs9p38&list=PL3FW7Lu3i5Jsnh1rnUwq_TcylNr7EkRe6&index=2\n",
    "\n",
    "La clase está buena aunque tiene bastante matemática. Es más que nada para que se entienda el concepto igualmente"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clasificadores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación van a realizar experimentos con tres clasificadores básicos. Para cada uno van a tener que probar una serie de hiperparámetros. Les incluyo la documentación para que puedan leer qué es cada hiperparámetro que están probando. Luego de cada corrida, evaluan el clasificador con cuatro métricas: Accuracy Score, F1 micro, F1 macro y el promedio del F1 de la clase Favor con el F1 de la clase Against. La idea es que vayan cambiando los valores de un hiperparámetro dejando fijos el resto y vean cómo ese cambio impacta en las métricas. Finalmente, para cada clasificador escriban un pequeño informe planteando cuan sensible es cada parámetro respecto de cada métrica, por qué piensan que es así de sensible y cuales son los mejores valores que encontraron. Finalmente, elijan el clasificador que les parezca más adecuado para esta tarea y justifiquen su elección. Para ese clasificador que hayan elegido van a probar luego, una busqueda más exhaustiva de hiperparámetros usando Grid Search. Este procedimiento deben hacerlo **al menos** para **dos de los cuatro** datasets con los que venimos trabajando (aborto, aborto balanceado, cambio climático y feminismo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perceptron"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Perceptron.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Perceptron(alpha=0.001, class_weight=None, early_stopping=False, eta0=1.0,\n",
       "           fit_intercept=True, max_iter=1000, n_iter_no_change=5, n_jobs=None,\n",
       "           penalty='l1', random_state=0, shuffle=True, tol=1,\n",
       "           validation_fraction=0.1, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train = abortion_train[\"Stance\"]\n",
    "y_test = abortion_test[\"Stance\"]\n",
    "\n",
    "# En principio, pueden utilizar el módulo que sigue, con los parámetros por defecto y los que definan a continuación:\n",
    "penalty = 'l1'  # No cambia con las otras opciones (None, l2, y elasticnet)\n",
    "alpha = 0.001   # A medida que aumenta es test da mejor que el train\n",
    "                # A medida que disminuye overfittea\n",
    "max_iter = 1000  # No cambia  \n",
    "tol = 1  # No parece ser muy sensible\n",
    "\n",
    "model = Perceptron(penalty = penalty, alpha = alpha, fit_intercept=True, max_iter = max_iter, tol = tol, shuffle=True, random_state=0, class_weight=None, warm_start=False)\n",
    "model.fit(VEC_train_abortion, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy para conjunto de entrenamiento: 0.67\n",
      "F1 micro para conjunto de entrenamiento: 0.67\n",
      "F1 macro para conjunto de entrenamiento: 0.59\n",
      "F1 average para conjunto de entrenamiento: 0.64\n",
      "Accuracy para conjunto de test: 0.60\n",
      "F1 micro para conjunto de test: 0.60\n",
      "F1 macro para conjunto de test: 0.46\n",
      "F1 average para conjunto de test: 0.59\n"
     ]
    }
   ],
   "source": [
    "y_pred_train =  model.predict(VEC_train_abortion)\n",
    "accuracy_train = accuracy_score(y_train, y_pred_train)\n",
    "f1_train_micro = f1_score(y_train, y_pred_train, average=\"micro\", labels=[\"NONE\", \"AGAINST\", \"FAVOR\"])\n",
    "f1_train_macro = f1_score(y_train, y_pred_train, average=\"macro\", labels=[\"NONE\", \"AGAINST\", \"FAVOR\"])\n",
    "f1_train = f1_score(y_train, y_pred_train, average=None, labels=[\"NONE\", \"AGAINST\", \"FAVOR\"])\n",
    "f1_train_average = (f1_score(y_train, y_pred_train, average=None, labels=[\"AGAINST\"]) + f1_score(y_train, y_pred_train, average=None, labels= [\"FAVOR\"]))/2\n",
    "\n",
    "print(\"Accuracy para conjunto de entrenamiento: %.2f\" % accuracy_train)\n",
    "print(\"F1 micro para conjunto de entrenamiento: %.2f\" % f1_train_micro)\n",
    "print(\"F1 macro para conjunto de entrenamiento: %.2f\" % f1_train_macro)\n",
    "print(\"F1 average para conjunto de entrenamiento: %.2f\" % f1_train_average)\n",
    "\n",
    "y_pred_test =  model.predict(VEC_test_abortion)\n",
    "accuracy_test = accuracy_score(y_test, y_pred_test)\n",
    "f1_test_micro = f1_score(y_test, y_pred_test, average=\"micro\", labels=[\"NONE\", \"AGAINST\", \"FAVOR\"])\n",
    "f1_test_macro = f1_score(y_test, y_pred_test, average=\"macro\", labels=[\"NONE\", \"AGAINST\", \"FAVOR\"])\n",
    "f1_test = f1_score(y_test, y_pred_test, average=None, labels=[\"NONE\", \"AGAINST\", \"FAVOR\"])\n",
    "f1_test_average = (f1_score(y_test, y_pred_test, average=None, labels=[\"AGAINST\"]) + f1_score(y_test, y_pred_test, average=None, labels= [\"FAVOR\"]))/2\n",
    "\n",
    "print(\"Accuracy para conjunto de test: %.2f\" % accuracy_test)\n",
    "print(\"F1 micro para conjunto de test: %.2f\" % f1_test_micro)\n",
    "print(\"F1 macro para conjunto de test: %.2f\" % f1_test_macro)\n",
    "print(\"F1 average para conjunto de test: %.2f\" % f1_test_average)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-NN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='cosine',\n",
       "                     metric_params=None, n_jobs=None, n_neighbors=5, p=2,\n",
       "                     weights='uniform')"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_neighbors = 5 # Cantidad de vecinos a tener en cuenta\n",
    "                # A medida que disminuye overfittea y a medida que aumenta los scores empeoran\n",
    "metric = 'cosine'     # Medida de distancia. Algunas opciones: cosine, euclidean, manhattan.\n",
    "\n",
    "model = KNeighborsClassifier(n_neighbors=n_neighbors, metric=metric)\n",
    "model.fit(VEC_train_abortion, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy para conjunto de entrenamiento: 0.73\n",
      "F1 micro para conjunto de entrenamiento: 0.73\n",
      "F1 macro para conjunto de entrenamiento: 0.66\n",
      "F1 average para conjunto de entrenamiento: 0.70\n",
      "Accuracy para conjunto de test: 0.67\n",
      "F1 micro para conjunto de test: 0.67\n",
      "F1 macro para conjunto de test: 0.54\n",
      "F1 average para conjunto de test: 0.63\n"
     ]
    }
   ],
   "source": [
    "y_pred_train =  model.predict(VEC_train_abortion)\n",
    "accuracy_train = accuracy_score(y_train, y_pred_train)\n",
    "f1_train_micro = f1_score(y_train, y_pred_train, average=\"micro\", labels=[\"NONE\", \"AGAINST\", \"FAVOR\"])\n",
    "f1_train_macro = f1_score(y_train, y_pred_train, average=\"macro\", labels=[\"NONE\", \"AGAINST\", \"FAVOR\"])\n",
    "f1_train = f1_score(y_train, y_pred_train, average=None, labels=[\"NONE\", \"AGAINST\", \"FAVOR\"])\n",
    "f1_train_average = f1_train_average = (f1_score(y_train, y_pred_train, average=None, labels=[\"AGAINST\"]) + f1_score(y_train, y_pred_train, average=None, labels= [\"FAVOR\"]))/2\n",
    "\n",
    "print(\"Accuracy para conjunto de entrenamiento: %.2f\" % accuracy_train)\n",
    "print(\"F1 micro para conjunto de entrenamiento: %.2f\" % f1_train_micro)\n",
    "print(\"F1 macro para conjunto de entrenamiento: %.2f\" % f1_train_macro)\n",
    "print(\"F1 average para conjunto de entrenamiento: %.2f\" % f1_train_average)\n",
    "\n",
    "y_pred_test =  model.predict(VEC_test_abortion)\n",
    "accuracy_test = accuracy_score(y_test, y_pred_test)\n",
    "f1_test_micro = f1_score(y_test, y_pred_test, average=\"micro\", labels=[\"NONE\", \"AGAINST\", \"FAVOR\"])\n",
    "f1_test_macro = f1_score(y_test, y_pred_test, average=\"macro\", labels=[\"NONE\", \"AGAINST\", \"FAVOR\"])\n",
    "f1_test = f1_score(y_test, y_pred_test, average=None, labels=[\"NONE\", \"AGAINST\", \"FAVOR\"])\n",
    "f1_test_average = (f1_score(y_test, y_pred_test, average=None, labels=[\"AGAINST\"]) + f1_score(y_test, y_pred_test, average=None, labels= [\"FAVOR\"]))/2\n",
    "\n",
    "print(\"Accuracy para conjunto de test: %.2f\" % accuracy_test)\n",
    "print(\"F1 micro para conjunto de test: %.2f\" % f1_test_micro)\n",
    "print(\"F1 macro para conjunto de test: %.2f\" % f1_test_macro)\n",
    "print(\"F1 average para conjunto de test: %.2f\" % f1_test_average)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=10,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "penalty =  'l2' # Tipo de regularización: l1 (valor absoluto), l2 (cuadrados).\n",
    "                  # Con none overfitea, l1 y elasticnet no los soporta\n",
    "alpha =  10 # Parámetro de regularización. También denominado como parámetro `lambda`. Debe ser mayor que 0.\n",
    "            # A medida que disminuye overfitea y a medida que aumenta empeora\n",
    "max_iter =  10 # Cantidad máxima de iteraciones del algoritmo.\n",
    "               # No es sensible para valores muy altos y para valores bajos empeora\n",
    "tol =  0.0001 # Precisión del algoritmo (error mínimo entre una iteración y la siguiente).\n",
    "        # Para valores chicos no es sensible y para valores altos empeora\n",
    "model = LogisticRegression(penalty=penalty, C=1./alpha, max_iter=max_iter, tol=tol)\n",
    "model.fit(VEC_train_abortion, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy para conjunto de entrenamiento: 0.71\n",
      "F1 micro para conjunto de entrenamiento: 0.71\n",
      "F1 macro para conjunto de entrenamiento: 0.62\n",
      "F1 average para conjunto de entrenamiento: 0.68\n",
      "Accuracy para conjunto de test: 0.66\n",
      "F1 micro para conjunto de test: 0.66\n",
      "F1 macro para conjunto de test: 0.48\n",
      "F1 average para conjunto de test: 0.63\n"
     ]
    }
   ],
   "source": [
    "y_pred_train =  model.predict(VEC_train_abortion)\n",
    "accuracy_train = accuracy_score(y_train, y_pred_train)\n",
    "f1_train_micro = f1_score(y_train, y_pred_train, average=\"micro\", labels=[\"NONE\", \"AGAINST\", \"FAVOR\"])\n",
    "f1_train_macro = f1_score(y_train, y_pred_train, average=\"macro\", labels=[\"NONE\", \"AGAINST\", \"FAVOR\"])\n",
    "f1_train = f1_score(y_train, y_pred_train, average=None, labels=[\"NONE\", \"AGAINST\", \"FAVOR\"])\n",
    "f1_train_average = f1_train_average = (f1_score(y_train, y_pred_train, average=None, labels=[\"AGAINST\"]) + f1_score(y_train, y_pred_train, average=None, labels= [\"FAVOR\"]))/2\n",
    "\n",
    "print(\"Accuracy para conjunto de entrenamiento: %.2f\" % accuracy_train)\n",
    "print(\"F1 micro para conjunto de entrenamiento: %.2f\" % f1_train_micro)\n",
    "print(\"F1 macro para conjunto de entrenamiento: %.2f\" % f1_train_macro)\n",
    "print(\"F1 average para conjunto de entrenamiento: %.2f\" % f1_train_average)\n",
    "\n",
    "y_pred_test =  model.predict(VEC_test_abortion)\n",
    "accuracy_test = accuracy_score(y_test, y_pred_test)\n",
    "f1_test_micro = f1_score(y_test, y_pred_test, average=\"micro\", labels=[\"NONE\", \"AGAINST\", \"FAVOR\"])\n",
    "f1_test_macro = f1_score(y_test, y_pred_test, average=\"macro\", labels=[\"NONE\", \"AGAINST\", \"FAVOR\"])\n",
    "f1_test = f1_score(y_test, y_pred_test, average=None, labels=[\"NONE\", \"AGAINST\", \"FAVOR\"])\n",
    "f1_test_average = (f1_score(y_test, y_pred_test, average=None, labels=[\"AGAINST\"]) + f1_score(y_test, y_pred_test, average=None, labels= [\"FAVOR\"]))/2\n",
    "\n",
    "print(\"Accuracy para conjunto de test: %.2f\" % accuracy_test)\n",
    "print(\"F1 micro para conjunto de test: %.2f\" % f1_test_micro)\n",
    "print(\"F1 macro para conjunto de test: %.2f\" % f1_test_macro)\n",
    "print(\"F1 average para conjunto de test: %.2f\" % f1_test_average)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El algoritmo que obtuve mejores métricas es el de los vecinos más cercanos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=6, error_score=nan,\n",
       "             estimator=KNeighborsClassifier(algorithm='auto', leaf_size=30,\n",
       "                                            metric='minkowski',\n",
       "                                            metric_params=None, n_jobs=None,\n",
       "                                            n_neighbors=5, p=2,\n",
       "                                            weights='uniform'),\n",
       "             iid='deprecated', n_jobs=None,\n",
       "             param_grid={'metric': ['cosine', 'manhattan', 'euclidean',\n",
       "                                    'minkowvski'],\n",
       "                         'n_neighbors': [1, 2, 3, 4, 5, 10, 20, 100, 200]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring='f1_micro', verbose=0)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejor conjunto de parámetros:\n",
      "{'metric': 'cosine', 'n_neighbors': 20}\n",
      "\n",
      "\n",
      "Puntajes de la grilla:\n",
      "\n",
      "\n",
      "Reporte de clasificación para el mejor clasificador (sobre conjunto de evaluación):\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     AGAINST       0.71      0.89      0.79       189\n",
      "       FAVOR       0.39      0.26      0.31        46\n",
      "        NONE       0.36      0.09      0.14        45\n",
      "\n",
      "    accuracy                           0.66       280\n",
      "   macro avg       0.49      0.41      0.41       280\n",
      "weighted avg       0.60      0.66      0.61       280\n",
      "\n",
      "\n",
      "================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Para la búsqueda de los mejores parámetros, por ejemplo de logistic regression, pueden usar:\n",
    "\n",
    "exploring_params = {\n",
    "        'n_neighbors': [ 1, 2, 3, 4, 5, 10, 20, 100, 200], # Inversa del coeficiente de regularización\n",
    "        'metric': ['cosine', 'manhattan', 'euclidean', 'minkowvski'],  # Cantidad de iteraciones\n",
    "    }\n",
    "\n",
    "m = KNeighborsClassifier()\n",
    "n_cross_val =  6 # Seleccionar folds\n",
    "scoring = \"f1_micro\"\n",
    "model = GridSearchCV(m, exploring_params, cv=n_cross_val, scoring=scoring)\n",
    "    \n",
    "model.fit(VEC_train_abortion, y_train)\n",
    "\n",
    "print(\"Mejor conjunto de parámetros:\")\n",
    "print(model.best_params_, end=\"\\n\\n\")\n",
    "print()\n",
    "print(\"Puntajes de la grilla:\", end=\"\\n\\n\")\n",
    "means = model.cv_results_['mean_test_score']\n",
    "stds = model.cv_results_['std_test_score']\n",
    "print()\n",
    "print(\"Reporte de clasificación para el mejor clasificador (sobre conjunto de evaluación):\", end=\"\\n\\n\")\n",
    "y_true, y_pred = y_test, model.predict(VEC_test_abortion)\n",
    "print(classification_report(y_true, y_pred), end=\"\\n\\n\")\n",
    "\n",
    "print(\"================================================\", end=\"\\n\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
